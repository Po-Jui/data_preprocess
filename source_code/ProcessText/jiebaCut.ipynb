{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " author:jjk\n",
    " datetime:2019/11/26\n",
    " coding:utf-8\n",
    " project name:Pycharm_workstation\n",
    " Program function: jieba分词操作详解\n",
    " \n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "支持三种分词模式与特点：\n",
    "    精确模式：试图将句子最精确地切开，适合文本分析；\n",
    "    全模式：把句子中所有的可以成词的词语都扫描出来，速度非常快，但是不能解决歧义；\n",
    "    搜索引擎模式：在精确模式的基础上对长词再次切分，提高召回率，适用于搜索引擎。\n",
    "    支持繁体分词\n",
    "    支持自定义词典\n",
    "安装方法：\n",
    "    自动安装：pip install jieba\n",
    "    半自动安装：下载http://pypi.python.org/pypi/jieba/解压后运行python setup.py install\n",
    "    手动安装：将jieba 目录放置于当前目录或者site-packages目录，通过 import jieba 来引用\n",
    "核心算法：\n",
    "    基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图（DAG）\n",
    "    采用了动态规划查找最大概率路径，找出基于词频的最大切分组合，对于未登录词，采用了基于汉字成词能力的HMM模型，使用了Viterbi算法\n",
    "\n",
    "主要功能：\n",
    "    jieba.cut三个输入参数：待分词的字符串；cut_a11参数是否全模式；HMM参数是否是HMM模型\n",
    "    jieba.cut_for_search两个参数：待分词的字符串；是否HMM模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细\n",
    "    jieba.lcut以及 jieba.lcut_for_search直接返回list\n",
    "    jieba.Tokenizer（dictionary=DEFAULT_DICT）新建自定义分词器，可用于同时使用不同词典。 \n",
    "    jieba.dt为默认分词器\n",
    "    \n",
    "\"\"\"\n",
    "import jieba,os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "1.分词\n",
      "----------------------------------------\n",
      "Full Mode:贾,继,康,来自,昆明,明理,理工,理工大,理工大学,工大,大学\n"
     ]
    }
   ],
   "source": [
    "#********************1 结巴中文分词基本操作***********************************\n",
    "# 1、全模式、扫描所有可能成词的词语，速度非常快，不能解决歧义问题\n",
    "print('='*40)\n",
    "print('1.分词')\n",
    "print('-'*40)\n",
    "seg_list = jieba.cut('贾继康来自昆明理工大学',cut_all=True) # cut_all=True采用全模式\n",
    "print('Full Mode:' + ','.join(seg_list)) # 全模式就是将所有可能构成词的分割开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "1.分词\n",
      "----------------------------------------\n",
      "Default Mode:贾继康,来自,昆明,理工大学\n"
     ]
    }
   ],
   "source": [
    "# 2、默认是精确模式，适合文本分析\n",
    "print('='*40)\n",
    "print('1.分词')\n",
    "print('-'*40)\n",
    "seg_list = jieba.cut('贾继康来自昆明理工大学',cut_all=False) # 默认的分词方式\n",
    "print('Default Mode:' + ','.join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "1.分词\n",
      "----------------------------------------\n",
      "搜索引擎方式：贾,继,康,来自,昆明,理工,工大,大学,理工大,理工大学\n"
     ]
    }
   ],
   "source": [
    "# 3、搜索引擎模式，对长词再次切分，提高召回率，适合用于搜索引擎分词\n",
    "# \n",
    "print('='*40)\n",
    "print('1.分词')\n",
    "print('-'*40)\n",
    "seg_list = jieba.cut_for_search('贾继康来自昆明理工大学',HMM=False)\n",
    "print('搜索引擎方式：' + ','.join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "2.添加自定义词典/调整词典\n",
      "----------------------------------------\n",
      "原文档:如果/放到/数据库/中/将/出错\n",
      "488\n",
      "改进文档:如果/放到/数据库/中/将/出错\n",
      "\n",
      "原文档：\t「/台中/」/正确/应该/不会/被/切开\n",
      "70\n",
      "改进文档：\t「/台中/」/正确/应该/不会/被/切开\n"
     ]
    }
   ],
   "source": [
    "print('='*40)\n",
    "print('2.添加自定义词典/调整词典')\n",
    "print('-'*40)\n",
    "\n",
    "seg_list = jieba.cut('如果放到数据库中将出错',HMM=False)\n",
    "# 如果/放到/数据库/中/将/出错\n",
    "print('原文档:' + '/'.join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut('如果放到数据库中将出错',HMM=False)\n",
    "print(jieba.suggest_freq(('中','将'),True)) # 调整词典-实现‘中将拆分’\n",
    "print('改进文档:' + '/'.join(seg_list))\n",
    "\n",
    "# 合成\n",
    "print('\\n原文档：\\t'+'/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False))) #「/台/中/」/正确/应该/不会/被/切开\n",
    "print(jieba.suggest_freq('台中', True))\n",
    "print('改进文档：\\t'+'/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False))) #「/台中/」/正确/应该/不会/被/切开\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "加载自定义分词词典：\n",
      "今天很高兴/ 在/ 慕课网/ 和/ 大家/ 交流学习\n"
     ]
    }
   ],
   "source": [
    "#********************2 加载自定义分词词典***********************************\n",
    "#sys.path.append(../)\n",
    "jieba.load_userdict(\"../dataSet/StopWord/user_dict.txt\") # 加载词典\n",
    "\n",
    "seg_list1 = jieba.cut(\"今天很高兴在慕课网和大家交流学习\")\n",
    "print('\\n\\n加载自定义分词词典：\\n' + \"/ \".join(seg_list1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "3. 关键词提取\n",
      "----------------------------------------\n",
      " TF-IDF\n",
      "----------------------------------------\n",
      "欧亚 0.7300142700289363\n",
      "吉林 0.659038184373617\n",
      "置业 0.4887134522112766\n",
      "万元 0.3392722481859574\n",
      "增资 0.33582401985234045\n",
      "4.3 0.25435675538085106\n",
      "7000 0.25435675538085106\n",
      "2013 0.25435675538085106\n",
      "139.13 0.25435675538085106\n",
      "实现 0.19900979900382978\n",
      "----------------------------------------\n",
      " TextRank\n",
      "----------------------------------------\n",
      "吉林 1.0\n",
      "欧亚 0.9966893354178172\n",
      "置业 0.6434360313092776\n",
      "实现 0.5898606692859626\n",
      "收入 0.43677859947991454\n",
      "增资 0.4099900531283276\n",
      "子公司 0.35678295947672795\n",
      "城市 0.34971383667403655\n",
      "商业 0.34817220716026936\n",
      "业务 0.3092230992619838\n"
     ]
    }
   ],
   "source": [
    "print('='*40)\n",
    "print('3. 关键词提取')\n",
    "print('-'*40)\n",
    "print(' TF-IDF')\n",
    "print('-'*40)\n",
    "\n",
    "'''\n",
    "extract_tags(sentence, topK=20, withWeight=False, allowPOS=())\n",
    "sentence 为待提取的文本\n",
    "topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20\n",
    "withWeight 为是否一并返回关键词权重值，默认值为 False\n",
    "allowPOS 仅包括指定词性的词，默认值为空，即不筛选\n",
    "jieba.analyse.TFIDF(idf_path=None) 新建 TFIDF 实例，idf_path 为 IDF 频率文件\n",
    "'''\n",
    "import jieba.analyse\n",
    "s = \"此外，公司拟对全资子公司吉林欧亚置业有限公司增资4.3亿元，增资后，吉林欧亚置业注册资本由7000万元增加到5亿元。吉林欧亚置业主要经营范围为房地产开发及百货零售等业务。目前在建吉林欧亚城市商业综合体项目。2013年，实现营业收入0万元，实现净利润-139.13万元。\"\n",
    "for x, w in jieba.analyse.extract_tags(s,10, withWeight=True):\n",
    "    print('%s %s' % (x, w)) \n",
    "\n",
    "print('-'*40)\n",
    "print(' TextRank')\n",
    "print('-'*40)\n",
    "# 文本排名\n",
    "for x, w in jieba.analyse.textrank(s, 10,withWeight=True):\n",
    "    print('%s %s' % (x, w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "4. 词性标注\n",
      "----------------------------------------\n",
      "我 r\n",
      "爱 v\n",
      "北京 ns\n",
      "天安门 ns\n",
      "========================================\n",
      "6. Tokenize: 返回词语在原文的起止位置\n",
      "----------------------------------------\n",
      " 默认模式\n",
      "----------------------------------------\n",
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n",
      "----------------------------------------\n",
      " 搜索模式\n",
      "----------------------------------------\n",
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限\t\t start: 6 \t\t end:8\n",
      "word 公司\t\t start: 8 \t\t end:10\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg\n",
    "print('='*40)\n",
    "print('4. 词性标注')\n",
    "print('-'*40)\n",
    "\n",
    "words = jieba.posseg.cut(\"我爱北京天安门\")\n",
    "for word, flag in words:\n",
    "    print('%s %s' % (word, flag))\n",
    "\n",
    "print('='*40)\n",
    "print('6. Tokenize: 返回词语在原文的起止位置')\n",
    "print('-'*40)\n",
    "print(' 默认模式')\n",
    "print('-'*40)\n",
    "\n",
    "result = jieba.tokenize('永和服装饰品有限公司')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))\n",
    "\n",
    "print('-'*40)\n",
    "print(' 搜索模式')\n",
    "print('-'*40)\n",
    "\n",
    "result = jieba.tokenize('永和服装饰品有限公司', mode='search')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
